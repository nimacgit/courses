{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<div align=center>\n",
    "\t\t\t<font face=\"IranNastaliq\" size=30>\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t\t<p></p>\n",
    "ุจู ูุงู ุฎุฏุง\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t</font>\n",
    "\t\t\t<font color=#FF7500>\n",
    "ุฏุงูุดฺฏุงู ุตูุนุช ุดุฑู - ุฏุงูุดฺฉุฏู ูููุฏุณ ฺฉุงููพูุชุฑ\n",
    "            </font>\n",
    "\t\t\t<p></p>\n",
    "\t\t\t<font color=blue>\n",
    "ููุด ูุตููุน\n",
    "            </font>\n",
    "\t\t\t<br />\n",
    "\t\t\t<br />\n",
    "ูพุงุฒ ฑณนน\n",
    "\t\t</div>\n",
    "\t\t<div align=center>\n",
    "\t\t    <font color=#FF7500 size=6>\n",
    "\t\t\t    <br />\n",
    "ุชูุฑู ุดุดูุ ุจุฎุด ุฏูู\n",
    "                ุณูุงู ุนูู\n",
    "            \t<br/>\n",
    "\t\t\t</font>\n",
    "        </div>\n",
    "\t</font>\n",
    "    <hr/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:200%;\">\n",
    "\t<font face=\"XB Zar\" size=3>\n",
    "ุฏุฑ ุงู ุชูุฑู ุจุง ูพููุฏู ฺฏุงูโูุง ูุดุฎุต ุดุฏู ฺฉ ุดุจฺฉู ุนุตุจ ุฏููุงู ุจุง ูุนูุงุฑ ุณุงุฏู ูพุงุฏูโุณุงุฒ ูโฺฉูุฏ. ุฏุฑ ุงุจุชุฏุง ุจุง ุงุฌุฑุง ฺฉุฑุฏู ูุทุนู ฺฉุฏ ุชูุธูุงุช ุงููู ุงูุฌุงู ูโุดููุฏ. ุฏุฑ ููฺฏุงู ุงูุฌุงู ุชูุฑู ู ูุฑุงุฌุนู ุจู ูุงู ฺฉุฏ ุฏุฑ ุขู ูุณูุชโูุง TODO ฺฏุฐุงุดุชู ุดุฏู ฺฉู ุดูุง ุจุงุฏ ุขู ูุณูุชโูุง ุฑุง ูพุฑ ฺฉูุฏ ู ุชูุถุญุงุช ุนูุงูู ุจุฑ ุชูุถุญุงุช ุงู ูุงู jupyter ูุฒ ุฏุฑ ุขูุฌุง ุฏุงุฏู ุดุฏู.<br>\n",
    "        ุงู ุชูุฑู ุจุฑฺฏุฑูุชู ุงุฒ ุชูุฑูโูุง ุฏุฑุณ cs231n ูโุจุงุดุฏ.\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# A bit of setup\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neural_net import TwoLayerNet\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:200%;\">\n",
    "\t<font face=\"XB Zar\" size=3>\n",
    "        ฺฉูุงุณ \n",
    "   TwoLayerNet ุฏุฑ ูุงู neural_net.py ูุชุนูู ุจู ูุฏู ฺฉู ูุตุฏ ุทุฑุงุญ ุขู ุฑุง ุฏุงุฑุฏ ูโุจุงุดุฏ ฺฉู ฺฉุฏโูุง ุฎูุฏ ุฑุง ุฏุฑ ุงู ูุงู ูพุงุฏู ุณุงุฒ ูโฺฉูุฏ.\n",
    "    ูพุงุฑุงูุชุฑโูุง ุดุจฺฉู ุฏุฑ self.params ุฐุฎุฑู ูโุดููุฏ. ฺฉุฏ ุฒุฑ ุจู ุชุณุช ฺฉุฑุฏู ฺฉุฏ ุดูุง ุฏุฑ ุญู ูพุงุฏูโุณุงุฒ ฺฉูฺฉ ูโฺฉูุฏ ุจูุงุจุฑุงู ุจุฏูู ุงุฌุงุฏ ุชุบุฑ ุฏุฑ ุจููฺฉ ุฒุฑ ุขู ุฑุง ุงุฌุฑุง ฺฉูุฏ.\n",
    "        <br>\n",
    "        ูุนูุงุฑ ุงู ุดุจฺฉู ุจู ุตูุฑุช ุฒุฑ ูโุจุงุดุฏ:<br>\n",
    "        <ul>\n",
    "            <li>ูุฑูุฏ ุฏุงุฑุง D ูฺฺฏ ูโุจุงุดุฏ ุณูพุณ ูุงูโ ูุฎู ุฏุงุฑุง H ุนุฏุฏ ูพุฑุณูพุชุฑูู ูโุจุงุดุฏ. ุงู ุดุจฺฉู ุฏุฑ ููุงุช ููุฏุงุฑ c ููุฏุงุฑ ุฎุฑูุฌ ูโุฏูุฏ ฺฉู ุชุนุฏุงุฏ ฺฉูุงุณโูุง ฺฉู ูโุฎูุงูู ุดูุงุณุง ฺฉูู ูโุจุงุดุฏ. ุฏูุช ฺฉูุฏ ฺฉู ุงู ุณู ููุฏุงุฑ ุจู ุดุจฺฉู ุจู ุนููุงู ูุฑูุฏ ุฏุงุฏู ูโุดูุฏ ู ุจุฑ ุงุณุงุณ ุขู ุดุจฺฉู ุณุงุฎุชู ูโุดูุฏ.</li>\n",
    "            <li>\n",
    "                ุฏุฑ ุงู ุดุจฺฉู ุจุนุฏ ุงุฒ ูุงูโ ุงูู ุงุฒ ุชุงุจุน ูุนุงูโุณุงุฒ relu ุงุณุชูุงุฏู ูโฺฉูู ู ุฏุฑ ููุงุช ุจุฑุง ูุญุงุณุจู ฺฉุฑุฏู ูุฒููโ ุดุจฺฉู ุนุตุจ ุจุง ุชูุฌู ุจู ุงูฺฉู c ููุฏุงุฑ ุฎุฑูุฌ ุฏุงุฑู ุงุฒ ุชุงุจุน ูุฒููโ softmax ุงุณุชูุงุฏู ูโฺฉูู ฺฉู ุฏุฑ ุงุฏุงูู ุจุง ุขู ุขุดูุง ุฎูุงูุฏ ุดุฏ.\n",
    "                $$input ๐ก hidden\\, layer ๐ก relu ๐ก output\\, layer ๐ก softmax$$\n",
    "            </li>\n",
    "        </ul>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a small net and some toy data to check your implementations.\n",
    "# Note that we set the random seed for repeatable experiments.\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "    np.random.seed(0)\n",
    "    return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(num_inputs, input_size)\n",
    "    y = np.array([0, 1, 2, 2, 1])\n",
    "    return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:200%;\">\n",
    "\t<font face=\"XB Zar\" size=3>\n",
    "    <h3>ูุญุงุณุจูโ ุงูุชุงุฒุงุช</h3>\n",
    "        ุฏุฑ ุงู ูุฑุญูู ุจุงุฏ ูุณูุช ุงุฒ ุชุงุจุน loss ุฏุฑ ฺฉูุงุณ TwoLayerNet ุฑุง ูพุงุฏู ฺฉูุฏ(ุชุง ุฌุง ฺฉู ุงูุชุงุฒูุง ูุฑุจูุท ุจู ูุฑ ฺฉูุงุณ ุจุฏุณุช ูโุขูุฏ) ุฏุฑ ูุฑุญููโ ุจุนุฏ ุงูุชุงุฒุงุช ูุญุงุณุจู ุดุฏู ุชูุณุท ุดูุง ุจู ุชุงุจุน softmax loss ุฏุงุฏู ูโุดูุฏ ุชุง ูุฒููโ ุงู ุดุจฺฉู ุจุฏุณุช ุขุฏ.\n",
    "        <br>\n",
    "        ูพุณ ุงุฒ ุงุฌุฑุง ุจููฺฉ ุฒุฑ ููุฏุงุฑ ุจุฏุณุช ุขูุฏู ุชูุณุท ฺฉุฏ ุดูุง ู ููุฏุงุฑ ุงุตู ููุงุณู ูโุดููุฏ ู ุชูุงูุช ุขูโูุง ููุงุด ุฏุงุฏู ูโุดูุฏ. ุงู ููุฏุงุฑ ุจุงุฏ ุจุณุงุฑ ฺฉูฺฺฉ ุจุงุดุฏ (ุฏุฑ ุญุฏ $ 10^{-8}$)\n",
    "    <br> ุจู ูฺฉุงุช ฺฉู ุฒุฑ ูุฒ ุชูุฌู ฺฉูุฏ:\n",
    "        <ul>\n",
    "            <li>\n",
    "                w1 ูุฒูโูุง ูุฑุจูุท ุจู ูุงูโ ุงูู ูโุจุงุดุฏ ฺฉู ูุงุชุฑุณ ุงุฒ ุจุง ุดฺฉู (D,H) ูโุจุงุดุฏ ฺฉู D ุชุนุฏุงุฏ ูฺฺฏโูุง ูุฑูุฏโูุง ู H ุชุนุฏุงุฏ ูพุฑุณูพุชุฑููโูุง ูุงูโ ูุฎู ูโุจุงุดุฏ ู ููุฏุงุฑ ุขู ุฏุฑ self.params[\"w1\"] ุฐุฎุฑู ุดุฏู ุงุณุช.\n",
    "            </li>\n",
    "            <li>\n",
    "                b1 ุจุฑุง ุจุงุงุณโูุง ูุฑุจูุท ุจู ูุงูโ ุงูู ูโุจุงุดุฏ ฺฉู ุฏุงุฑุง ุดฺฉู (,H) ูโุจุงุดุฏ ฺฉู ููุฏุงุฑ ุขู ุฏุฑ self.params[\"b1\"] ุฏุฎุฑู ุดุฏู ุงุณุช.\n",
    "            </li>\n",
    "            <li>\n",
    "                w2 ูุงุชุฑุณ ูุฒูโูุง ุจุฑุง ูุงูโ ุฎุฑูุฌ ูโุจุงุดุฏ ฺฉู ุฏุงุฑุง ุดฺฉู (H,C) ูโุจุงุดุฏ ฺฉู ููุฏุงุฑ ุขู ุฏุฑ self.params[\"w2\"] ุฐุฎุฑู ุดุฏู ุงุณุช.\n",
    "            </li>\n",
    "            <li>\n",
    "                b2 ูุงุชุฑุณ ูุฑุจูุท ุจู ุจุงุงุณโูุง ูุงูโ ุฎุฑูุฌ ูโุจุงุดุฏ ฺฉู ุฏุงุฑุง ุดฺฉู (,C) ูโุจุงุดุฏ ฺฉู ููุฏุงุฑ ุขู ุฏุฑ self.params[\"b2\"] ุฐุฎุฑู ุดุฏู ุงุณุช.\n",
    "            </li>\n",
    "            <li>\n",
    "                H,C,D ูุฑูุฏโูุง ูุฏู ูโุจุงุดูุฏ.\n",
    "            </li>\n",
    "        </ul>\n",
    "        ูฺฉุงุช ุฒุฑ ูุฒ ุฏุฑุจุงุฑู ูุฑูุฏ ู ุฎุฑูุฌ ุชุงุจุน ููู ูโุจุงุดูุฏ:\n",
    "        <ul>\n",
    "            <li>\n",
    "                ูุฑูุฏ x ุฏุงุฏูโูุง ูุฑูุฏ ุจู ุดุจฺฉู ูโุจุงุดูุฏ ฺฉู ฺฉ ูุงุชุฑุณ ุจุง ุงุจุนุงุฏ (N,D) ูโุจุงุดูุฏ.\n",
    "            </li>\n",
    "            <li>\n",
    "                ูุฑูุฏ y ฺฉู ฺฉ ูุงุชุฑุณ ุจุง ุงุจุนุงุฏ (,N) ูโุจุงุดุฏ ูุดุงู ุฏููุฏูโ ฺฉูุงุณ ุฏุฑุณุช ูุฑุจูุท ุจู ูุฑูุฏโูุง x ูโุจุงุดุฏ. ุงู ูุฑูุฏ ูโุชูุงูุฏ ุจู ุชุงุจุน ุฏุงุฏู ุดูุฏ ุง ูุดูุฏ ุฏุฑ ุตูุฑุช ฺฉู ุฏุงุฏู ูุดูุฏ ุงู ุชุงุจุน ููุท ุงูุชุงุฒุงุช ุฑุง ูุญุงุณุจู ูโฺฉูุฏ ู ุฎุฑูุฌ ูโุฏูุฏ ู ุฏุฑ ุตูุฑุช ฺฉู ุฏุงุฏู ุดูุฏ ุจุง ุงุณุชูุงุฏู ุงุฒ ุขูโูุง ู ุงูุชุงุฒุงุช ุจุฏุณุช ุขูุฏู ููุงุฏุฑ ฺฏุฑุงุฏุงู ู ูุฒูู ุฑุง ูุฒ ูุญุงุณุจู ูโฺฉูุฏ ู ุขูโูุง ุฑุง ุฎุฑูุฌ ูโุฏูุฏ.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = net.loss(X)\n",
    "print('Your scores:')\n",
    "print(scores)\n",
    "print()\n",
    "print('correct scores:')\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print(correct_scores)\n",
    "print()\n",
    "\n",
    "# The difference should be very small. We get < 1e-7\n",
    "print('Difference between your scores and correct scores:')\n",
    "print(np.sum(np.abs(scores - correct_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:200%;\">\n",
    "\t<font face=\"XB Zar\" size=3>\n",
    "    <h3>ูุญุงุณุจูโ ูุฒูู</h3>\n",
    "    ุฏุฑ ุงู ูุฑุญูู ูุฒูู ุดุจฺฉู ุนุตุจ ุจุง ุงุณุชูุงุฏู ุงุฒ ุงูุชุงุฒุงุช ฺฉู ุฏุฑ ูุฑุญููโ ูุจู ุจุฏุณุช ุขูุฑุฏุฏ ุชูุณุท ุชุงุจุน ูุฒููโ softmax ูุญุงุณุจู ูโุดูุฏ (ููฺูุงู ุฏุฑ ููุงู ุชุงุจุน loss ฺฉู ุฏุฑ ูุฑุญูู ูุจู ุฏุฑ ุญุงู ูพุฑ ฺฉุฑุฏู ูุณูุช ุงุฒ ุขู ุจูุฏุฏ ุงู ฺฉุงุฑ ุฑุง ุงูุฌุงู ูโุฏูุฏ). ุฏุฑ ุงู ูุฑุญูู ุดูุง ุตุฑูุง ุจุงุฏ ุจู ูุญุงุณุจุงุช ุงูุฌุงู ุดุฏู ููุฏุงุฑ ูุฑุจูุท ุจู regularization ุฑุง ุงุถุงูู ฺฉูุฏ.(ููุฏุงุฑ loss ฺฉู ูุญุงุณุจู ุดุฏู ุงุณุช ุฑุง ุจุงุฏ ุขูพุฏุช ฺฉูุฏ) ุชุงุจุน softmax ุจู ุตูุฑุช ุฒุฑ ุงุณุช:(ููุฏุงุฑ ุชูุงูุช ุจุงุฏ ุญุฏูุฏุง $10^{-13}$ ุจุงุดุฏ) \n",
    "    </font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L_i=-\\log{(\\frac{e^{f_{y_i}}}{\\sum_{k}{e^{f_{yk}}}})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.05)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "# should be very small, we get < 1e-12\n",
    "print('Difference between your loss and correct loss:')\n",
    "print(np.sum(np.abs(loss - correct_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:200%;\">\n",
    "\t<font face=\"XB Zar\" size=3>\n",
    "    <h3>ูุญุงุณุจูโ ฺฏุฑุงุฏุงู</h3>\n",
    "    ุฏุฑ ุงู ุจุฎุด ุจู ูุญุงุณุจูโ ฺฏุฑุงุฏุงู ูุง ูโูพุฑุฏุงุฒู. ุงู ฺฏุฑุงุฏุงูโูุง ุฑุง ุจุฑุง ุจุฑูุฒุฑุณุงู ฺฉุฑุฏู w1, w2, b1, b2 ูโุจุงุดุฏ ุชุง ูุฒููโ ุดุจฺฉูโ ุนุตุจ ฺฉุงูุด ุงุจุฏ ู ุฎุทุง ุขู ฺฉูุชุฑ ุดูุฏ. ุจุฑุง ุงูุฌุงู ูุญุงุณุจุงุช ุฏูุช ฺฉูุฏ ฺฉู ฺฏุฑุงุฏุงู ูุณูุช softmax ูุญุงุณุจู ุดุฏู ู ุฏุฑ dscores ูุฑุงุฑ ฺฏุฑูุชู ู ุดูุง ุจุงุฏ ุจุง ุงุณุชูุงุฏู ุงุฒ ุขู ู ุจุง ฺฉูฺฉ back-propagation ฺฏุฑุงุฏุงูโูุง W1,W2,b1,b2 ุฑุง ูุญุงุณุจู ฺฉูุฏ.<br>\n",
    "        ุจุฑุง ูพุงุฏูโุณุงุฒ ุงู ูุณูุช ุฏุฑ ุงุฏุงููโ ููุงู ุชุงุจุน loss ุงู ฺฉุงุฑ ุฑุง ุงูุฌุงู ุฏูุฏ ู ุฏุฑ ูุณูุช ูุฑุจูุทู ูพุงุฏูโุณุงุฒ ฺฉูุฏ. ุฏูุช ุดูุฏ ฺฉู ููุงุฏุฑ ุจุฏุณุช ุขูุฏู ุฑุง ุจุงุฏ ุฏุฑ ฺฉ dictionary ุจุฑฺฏุฑุฏุงูุฏ ฺฉู key ููุงู ููุฏุงุฑ ูโุจุงุดุฏ ู value ุจุงุฏ ูุงุชุฑุณ ฺฏุฑุงุฏุงู ุฑุง ูุฑุงุฑ ุฏูุฏ ุฏูุช ุดูุฏ ฺฉู ุงุจุนุงุฏ ูุงุชุฑุณ ฺฏุฑุงุฏุงู ุจุงุฏ ูุงููุฏ ุฎูุฏ ูุงุชุฑุณ ูุฒู ุง ุจุงุงุณโูุง ุจุงุดุฏ. ููฺูู ุฏุฑ ูุญุงุณุจุงุช ุฏุฎุงูุช ุฏุงุฏู L2 Regularization ุฑุง ูุฑุงููุด ูฺฉูุฏ.(ุฎุทุง ูุญุงุณุจุงุช ุจุงุฏ ุญุฏูุฏุง ุจุฑุงุจุฑ ุจุง $10^{-9}$ ุจุงุดุฏ) \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_check import eval_numerical_gradient\n",
    "\n",
    "# Use numeric gradient checking to check your implementation of the backward pass.\n",
    "# If your implementation is correct, the difference between the numeric and\n",
    "# analytic gradients should be less than 1e-8 for each of W1, W2, b1, and b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.05)\n",
    "\n",
    "# these should all be less than 1e-8 or so\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.05)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:200%;\">\n",
    "\t<font face=\"XB Zar\" size=3>\n",
    "    <h3>ุขููุฒุด ุดุจฺฉู ุนุตุจ</h3>\n",
    "        ุฏุฑ ุงู ูุณูุช ุจุฑุง ุขููุฒุด ุดุจฺฉู ุนุตุจ ุงุฒ stochastic gradient descent ุงุณุชูุงุฏู ูโฺฉูู. ุจุฑุง ุงูฺฉุงุฑ ุจุงุฏ ุชุงุจุน train ุฏุฑ ูุฏู ุฑุง ูพุงุฏูโุณุงุฒ ฺฉูุฏ. ุนูุงูู ุจุฑ ุชุงุจุน train ุจุงุฏ ุชุงุจุน predict ุฑุง ูุฒ ูพุงุฏู ฺฉูุฏ ุฒุฑุง ุฏุฑ ุญู ุขููุฒุด ุจุฑุง ูุญุงุณุจูโ ุฏูุช ุงุฒ ุงู ุชุงุจุน ุงุณุชูุงุฏู ูโุดูุฏ. ูพุณ ุงุฒ ูพุงุฏูโุณุงุฒ ุจููฺฉ ุฒุฑ ุฑุง ุงุฌุฑุง ฺฉูุฏ ููุฏุงุฑ ูุฒูู ุจุงุฏ ฺฉูุชุฑ ุงุฒ 0.02 ุดูุฏ.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_training_loss"
   },
   "outputs": [],
   "source": [
    "net = init_toy_model()\n",
    "stats = net.train(X, y, X, y,\n",
    "            learning_rate=1e-1, reg=5e-6,\n",
    "            num_iters=100, verbose=False)\n",
    "\n",
    "print('Final training loss: ', stats['loss_history'][-1])\n",
    "\n",
    "# plot the loss history\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:200%;\">\n",
    "\t<font face=\"XB Zar\" size=3>\n",
    "    <h3>ุฎูุงูุฏู ุฏุงุฏูโูุง</h3>\n",
    "    ุญุงู ฺฉู ูพุงุฏูโุณุงุฒ ูุณูุชโูุง ุจุงูุง ุชูุงู ุดุฏ ุจุง ุงุฌุฑุง ุจููฺฉ ุฒุฑ ุฏุงุฏูโูุง ฺฉู ุฏุฑ ูพูุดู datasets ูุฑุงุฑ ุฏุงุฏู ุดุฏู ุฎูุงูุฏู ูโุดููุฏ ู ุฏุฑ ูุฑุงุญู ุจุนุฏ ุจุฑ ุฑู ุขูโูุง ุดุจฺฉู ุฑุง ุขููุฒุด ูโุฏูู.\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "from data_utils import load_CIFAR10\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'datasets/cifar-10-batches-py'\n",
    "    \n",
    "    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "    try:\n",
    "        del X_train, y_train\n",
    "        del X_test, y_test\n",
    "        print('Clear previously loaded data.')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "        \n",
    "    # Subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    # Reshape data to rows\n",
    "    X_train = X_train.reshape(num_training, -1)\n",
    "    X_val = X_val.reshape(num_validation, -1)\n",
    "    X_test = X_test.reshape(num_test, -1)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir = \"rtl\" style=\"direction:rtl;line-height:200%;\">\n",
    "\t<font face=\"XB Zar\" size=3>\n",
    "    <h3>ุงุฏฺฏุฑ</h3>\n",
    "     ุจุง ุงุฌุฑุง ุจููฺฉ ุฒุฑ ฺฉ ุดุจฺฉู ุจุง ูพุงุฑุงูุชุฑโูุง ูุดุฎุต ุดุฏู ุขููุฒุด ุฏุงุฏู ูโุดูุฏ. ุฏูุช ุงู ุดุจฺฉู ุจุงุฏ ูุณุจุชุง ูพุงู ุจุงุดุฏ.(ุญุฏูุฏ ดธ ุฏุฑุตุฏ) ุฏูู ุงู ูโุจุงุดุฏ ฺฉู ุงู ุดุจฺฉู ุจุฑุง ุงู ูุฌููุนู ุฏุงุฏู ุขุณุงู ูโุจุงุดุฏ (ุฏูุช ุงู ุดุจฺฉู ุจู ูุณุจุช ุดุจฺฉูโูุง ุขุณุงูโุชุฑ ูุงููุฏ knn ุง ุดุจฺฉูโ ฺฉ ูุงูโ ุนุงุฏ ุจุงูุงุชุฑ ูโุจุงุดุฏ. ุจุฑุง ุงูฺฉู ุงู ุฏูุช ุงูุฒุงุด ุจุงุฏ ุงุฒ ุดุจฺฉูโูุง ูพฺุฏูโุชุฑ ฺฉู ุงุฒ ุณุทุญ ุงู ุฏุฑุณ ุจุงูุงุชุฑ ูโุจุงุดูุฏ ุงุณุชูุงุฏู ฺฉุฑุฏ (ูุงููุฏ ุดุจฺฉูโูุง ฺูุฏ ูุงู ู ุง CNNูุง) ฺฉู ูพุดููุงุฏ ูโุดูุฏ ุจุฑุง ูุทุงูุนู ุจุดุชุฑ ุจู ุขูโูุง ูุฑุงุฌุนู ฺฉูุฏ.<br>\n",
    "        ุจู ูฺฉุงุช ุฒุฑ ุชูุฌู ุฏุฑุจุงุฑูโ ุงู ุชุงุจุน train ุชูุฌู ฺฉูุฏ:\n",
    "        <ul>\n",
    "            <li>X: ฺฉ ุขุฑุงูโ numpy ุจุง ุงุจุนุงุฏ (N,D) ฺฉู ุฏุงุฏูโูุง ูุณูุช training ุฑุง ูุฑุงูู ูโฺฉูุฏ.</li>\n",
    "            <li>Y: ฺฉ ุขุฑุงูโ numpy ุจุง ุงุจุนุงุฏ (,N) ฺฉู ุฌูุงุจโูุง ูุฑุจูุท ุจู ูุณูุช training ุฑุง ูุฑุงูู ูโฺฉูุฏ ฺฉู ุณุทุฑ iุงู ุขู ุจู ุงู ูุนูุงุณุช ฺฉู ฺฉูุงุณ ุณุทุฑ iุงู X ฺู ูโุจุงุดุฏ.</li>\n",
    "            <li>X_val: ูุงููุฏ X ููุท ุจุฑุง ูุณูุช validation ุงุณุชูุงุฏู ูโุดูุฏ.</li>\n",
    "            <li>Y_val: ูุงููุฏ Y ููุท ุจุงุฑ ูุณูุช validation ุงุณุชูุงุฏู ูโุดูุฏ.</li>\n",
    "            <li>learning_rate: ูพุงุฑุงูุชุฑ ูุฑุจูุท ุณุฑุนุช ุขููุฒุด ูโุจุงุดุฏ.</li>\n",
    "            <li>learning_rate_decay: ุจุนุฏ ุงุฒ ูุฑ epoch ูพุงุฑุงูุชุฑ ูุฑุจูุท ุจู ุณุฑุนุช ุงุฏฺฏุฑ ุฏุฑ ุงู ููุฏุงุฑ ุถุฑุจ ูโุดูุฏ ู ฺฉูฺฺฉุชุฑ ูโุดูุฏ.</li>\n",
    "            <li>reg: ูพุงุฑุงูุชุฑ ูุฑุจูุท ุจู regularization ูโุจุงุดุฏ.</li>\n",
    "            <li>num_iters: ุชุนุฏุงุฏ iteration ูุง ฺฉู ุจุฑุง ุนูู ุจูููโุณุงุฒ ููุฑุฏ ุงุณุชูุงุฏู ูุฑุงุฑ ูโฺฏุฑุฏ.</li>\n",
    "            <li>verbos: ููุฏุงุฑ ุจููู ฺฉู ุชุตูู ูโฺฏุฑุฏ ุฏุฑ ุญู ุงุฌุฑุง ุงู ุชุงุจุน ุงุทูุงุนุช ฺุงูพ ุดููุฏ ุง ูู.</li>\n",
    "        </ul>\n",
    "        ููุงูุทูุฑ ฺฉู ฺฏูุชู ุดุฏ ุฏุฑ ุงู ูุณูุช ุจุงุฏ ุชุงุจุน predict ุฑุง ูุฒ ูพุงุฏูโุณุงุฒ ฺฉูุฏ ุจู ูฺฉุงุช ุฒุฑ ุฏุฑ ููุฑุฏ ุขู ุฏูุช ฺฉูุฏ:\n",
    "        <ul>\n",
    "            <li> ุฏุฑ ุงู ุชุงุจุน ุจุงุฏ ุจุง ุงุณุชูุงุฏู ุงุฒ ูุฒูโูุง ุงุฏฺฏุฑูุชู ุดุฏู ูพุดุจูโูุง ุฎูุฏ ุฑุง ุฏุฑุจุงุฑูโ ูุฑูุฏโูุง ุจุฑฺฏุฑุฏุงูุฏ.</li>\n",
    "            <li>X: ูุฑูุฏ ุจุง ุงุจุนุงุฏ (N,D) ูโุจุงุดุฏ.</li>\n",
    "            <li>y_pred: ุฎุฑูุฌ ุชุงุจุน ูโุจุงุดุฏ ฺฉู ูพุดุจูโูุง ูุฑุจูุท ุจู ูุฑูุฏ X ูโุจุงุดุฏ ู ุณุงุฒ ุขู ุจุฑุงุจุฑ ุจุง (,N) ูโุจุงุดุฏ.</li>\n",
    "        </ul>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 200\n",
    "num_classes = 10\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Train the network\n",
    "stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=1.0e-03, learning_rate_decay=0.95,\n",
    "            reg=0.15, verbose=True)\n",
    "\n",
    "# Predict on the validation set\n",
    "val_acc = (net.predict(X_val) == y_val).mean()\n",
    "print('Validation accuracy: ', val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
